---
title: Data Operations Manual - Key Processes - Creating A Collection
weight: 40103
---

# Creating A Collection

---

:warning: We are currently attempting to centralise both pipeline and collection configuration files. There are
two sets of instructions below depending on whether we have centralised the files for the collection you are 
altering. See for a list of collections that we are working on.
---

## non-centralised instructtions

This is needed when adding a dataset that doesn't belong to one of the collections
that already exist.

#### 1. Ensure the collection is noted in the specification

Not doing this won't result in any specific errors but it should be done to ensure that the list of collections in the specification is up to date. This should be done with some visiability from the standards team

#### 2. Use the [collection-template](https://github.com/digital-land/collection-template) to create a repository

The `collection-template` repo is a template repository which can be used to create
new collection repos. This is fairly simple using the Github UI. there is an option
to use the template to create a new repo if you navigate to the `collection-template`
page

#### 3. Update `.README`

Update the details in the readme file.

#### 4. Deactivate actions

The collection comes with the action ready to run every night. This should be paused until
your ready for it to be ran. This can be done by commenting out the following lines in the `.github
/workflows/run_caller.yaml` :

```
schedule:
- cron: 0 0 * * *
```

#### 5. Add endpoints, edit pipeline config files and test locally.

This is where you need to get the pipeline running locally. see our other
processes on this page for how to add data

#### 6. Re-activate actions

Once the collection is ready to be ran nightly uncomment the line from above in
the git workflow yaml file and it will start running nightly!


---
**Process Review**

Everything else is done so it's worth reviewing this process and seeing if there's
anyway we can improve it!

---

## centralised instructtions

This is needed when adding a dataset that doesn't belong to one of the collections
that already exist.

#### 1. Ensure the collection is noted in the specification

Not doing this won't result in any specific errors but it should be done to ensure that the list of collections in the specification is up to date. This should be done with some visiability from the standards team

#### 2. Create Collection and Pipeline folders in repo

The config repo currently contains collection and pipeline folders for each unique collection held within the pipeline. When adding the collection simply create folders named as they are displayed in the specification

#### 3. Add relevant files

Update the new collection folders by adding in the relevant files which are required of the pipeline ie in the collection folder you would have endpoint.csv, old-resource.csv and source.csv. And in the pipeline folder you will have the relevant configuration files.

#### 4. Add endpoints, edit pipeline config files and test locally.

This is where you need to get the pipeline running locally. see our other
processes on this page for how to add data

---
**Process Review**

Everything else is done so it's worth reviewing this process and seeing if there's
anyway we can improve it!

---